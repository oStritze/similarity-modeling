{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Detecting Kermit the Frog (Audio) </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert and extract raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34107999,), 22050)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import librosa\n",
    "\n",
    "def load(path, target):\n",
    "    command = \"ffmpeg -i\" + path + \"-ab 160k -ac 2 -ar 44100 -vn\" + target\n",
    "    subprocess.call(command, shell=True) \n",
    "    return librosa.load(target)\n",
    "    \n",
    "raw, sample_rate = load(\"../data/Muppets-02-01-01.avi\", \"../data/ep1_audio.wav\")\n",
    "raw.shape, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load ground truth\n",
    "truth_csv = pd.read_csv('../data/gt/gt_02_01_01.csv')\n",
    "truth = truth_csv.kermit_audio\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get second or timeframe from raw waveform\n",
    "def sec(sec, raw_wave=raw, sr=22050):\n",
    "    if type(sec) == int:\n",
    "        return raw_wave[sec*sr:(sec+1)*sr]\n",
    "    elif type(sec) == list and len(sec) == 1:\n",
    "        return raw_wave[sec[0]*sr:(sec[0]+1)*sr]\n",
    "    elif type(sec) == list and len(sec) == 2:\n",
    "        return raw_wave[sec[0]*sr:(sec[1]+1)*sr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 2640)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as stat\n",
    "import numpy as np\n",
    "\n",
    "def max_mfcc(wave_form, sr=22050):\n",
    "    features = []\n",
    "    for i in range(round(len(wave_form)/sr)):\n",
    "        mfcc = librosa.feature.mfcc(sec(i, wave_form))\n",
    "        # pick maximal value for each DCT dimension\n",
    "        features.append([max(dim) for dim in mfcc])\n",
    "    return features\n",
    "\n",
    "def all_mfcc(wave_form, sr=22050, flat=False):\n",
    "    features = []\n",
    "    for i in range(round(len(wave_form)/sr)):\n",
    "        mfcc = librosa.feature.mfcc(sec(i, wave_form))\n",
    "        d_mfcc = librosa.feature.delta(mfcc)\n",
    "        d2_mfcc = librosa.feature.delta(d_mfcc, order=2)\n",
    "\n",
    "        features.append(np.concatenate((mfcc, d_mfcc, d2_mfcc), axis=0))\n",
    "    \n",
    "    # complete last entry\n",
    "    fulld = features[0].shape[1]\n",
    "    fill = fulld - features[-1].shape[1]\n",
    "    features[-1] = np.concatenate((features[-1],np.zeros((features[0].shape[0],fill))), axis=1)\n",
    "    \n",
    "    # stack all of them on top of each other\n",
    "    features = np.stack(features)\n",
    "    \n",
    "    if flat:\n",
    "        nsamples, nx, ny = features.shape\n",
    "        return features.reshape((nsamples,nx*ny))\n",
    "    else:\n",
    "        return features\n",
    "    \n",
    "features = all_mfcc(raw, flat=True)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548, 2640)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features\n",
    "test_raw, test_sr = load('../data/Muppets-02-04-04.avi', '../data/ep2_audio.wav')\n",
    "test_features = all_mfcc(test_raw, flat=True)\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ground truth\n",
    "test_truth_csv = pd.read_csv('../data/gt/gt_02_04_04.csv.csv')\n",
    "test_truth = truth_csv.kermit_audio[:len(test_features)]\n",
    "test_truth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training precision 1.0\n",
      "testing precision 0.10416666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.metrics import precision_score as precision\n",
    "\n",
    "clf = MLP(random_state=1, hidden_layer_sizes=(1000, 200, 50)).fit(features, truth[:len(features)])\n",
    "\n",
    "# train accuracy\n",
    "print('training precision', precision(truth[:len(features)], clf.predict(features)))\n",
    "# test accuracy\n",
    "print('testing precision',precision(test_truth, clf.predict(test_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5874c711e4d444d960c727e322e3358"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9360058461217247\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9385990186867106\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9385990186867106\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9385990186867106\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9385990186867106\n",
      "\n",
      "Best pipeline: RandomForestClassifier(BernoulliNB(input_matrix, alpha=0.001, fit_prior=False), bootstrap=True, criterion=gini, max_features=0.2, min_samples_leaf=8, min_samples_split=4, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9231266149870802"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "pipeline_optimizer = TPOTClassifier(\n",
    "    generations=5, \n",
    "    population_size=20, \n",
    "    cv=5, \n",
    "    random_state=42, \n",
    "    verbosity=2)\n",
    "\n",
    "pipeline_optimizer.fit(features, truth[:len(features)])\n",
    "pipeline_optimizer.score(test_features, test_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer.export('tpot_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
