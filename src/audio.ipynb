{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Detecting Kermit the Frog (Audio) </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert and extract raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34107999,), 22050)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import librosa\n",
    "\n",
    "# create .wav files using\n",
    "# $ ffmpeg -i data/EPISODE.avi -ab 160k -ac 2 -ar 44100 -vn TARGET.wav\n",
    "\n",
    "raw, sample_rate = librosa.load(\"../data/ep1_audio.wav\")\n",
    "raw.shape, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load ground truth\n",
    "truth_csv = pd.read_csv('../data/gt/gt_02_01_01.csv')\n",
    "truth = truth_csv.kermit_audio\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get second or timeframe from raw waveform\n",
    "def sec(sec, raw_wave=raw, sr=22050):\n",
    "    if type(sec) == int:\n",
    "        return raw_wave[sec*sr:(sec+1)*sr]\n",
    "    elif type(sec) == list and len(sec) == 1:\n",
    "        return raw_wave[sec[0]*sr:(sec[0]+1)*sr]\n",
    "    elif type(sec) == list and len(sec) == 2:\n",
    "        return raw_wave[sec[0]*sr:(sec[1]+1)*sr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 2640)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as stat\n",
    "import numpy as np\n",
    "\n",
    "def max_mfcc(wave_form, sr=22050):\n",
    "    features = []\n",
    "    for i in range(round(len(wave_form)/sr)):\n",
    "        mfcc = librosa.feature.mfcc(sec(i, wave_form))\n",
    "        # pick maximal value for each DCT dimension\n",
    "        features.append([max(dim) for dim in mfcc])\n",
    "    return features\n",
    "\n",
    "def all_mfcc(wave_form, sr=22050, flat=False):\n",
    "    features = []\n",
    "    for i in range(round(len(wave_form)/sr)):\n",
    "        mfcc = librosa.feature.mfcc(sec(i, wave_form))\n",
    "        d_mfcc = librosa.feature.delta(mfcc)\n",
    "        d2_mfcc = librosa.feature.delta(d_mfcc, order=2)\n",
    "\n",
    "        features.append(np.concatenate((mfcc, d_mfcc, d2_mfcc), axis=0))\n",
    "    \n",
    "    # complete last entry\n",
    "    fulld = features[0].shape[1]\n",
    "    fill = fulld - features[-1].shape[1]\n",
    "    features[-1] = np.concatenate((features[-1],np.zeros((features[0].shape[0],fill))), axis=1)\n",
    "    \n",
    "    # stack all of them on top of each other\n",
    "    features = np.stack(features)\n",
    "    \n",
    "    if flat:\n",
    "        nsamples, nx, ny = features.shape\n",
    "        return features.reshape((nsamples,nx*ny))\n",
    "    else:\n",
    "        return features\n",
    "    \n",
    "features = all_mfcc(raw, flat=True)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548, 2640)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features\n",
    "test_raw, test_sr = librosa.load('../data/ep2_audio.wav')\n",
    "test_features = all_mfcc(test_raw, flat=True)\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Val Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1539, 2640)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract val features\n",
    "val_raw, val_sr = librosa.load('../data/ep3_audio.wav')\n",
    "val_features = all_mfcc(val_raw, flat=True)\n",
    "val_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist mfcc data\n",
    "np.savetxt(\"../data/ep1_flat_mfcc.csv\", features, delimiter=\",\")\n",
    "np.savetxt(\"../data/ep2_flat_mfcc.csv\", test_features, delimiter=\",\")\n",
    "np.savetxt(\"../data/ep3_flat_mfcc.csv\", val_features, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "ep1_data = pd.read_csv('../data/ep1_flat_mfcc.csv', sep=',', dtype=np.float64)\n",
    "ep1_target = pd.read_csv('../data/gt/gt_02_01_01.csv', sep=',')[:len(ep1_data)].kermit_audio\n",
    "ep2_data = pd.read_csv('../data/ep2_flat_mfcc.csv', sep=',', dtype=np.float64)\n",
    "ep2_target = pd.read_csv('../data/gt/gt_02_04_04.csv.csv', na_values=[None, ' ', '']).fillna(0).head(len(ep2_data)).kermit_audio\n",
    "ep3_data = pd.read_csv('../data/ep3_flat_mfcc.csv', sep=',', dtype=np.float64)\n",
    "ep3_target = pd.read_csv('../data/gt/gt_03_04_03.csv', sep=',')[:len(ep3_data)].kermit_audio\n",
    "\n",
    "# MERGE\n",
    "X = pd.concat([ep1_data, ep2_data, ep3_data])\n",
    "Y = pd.concat([ep1_target, ep2_target, ep3_target])\n",
    "\n",
    "# SPLIT\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train TPOT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.1 s, sys: 4.41 ms, total: 40.1 s\n",
      "Wall time: 40.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, criterion='entropy', max_features=1.0,\n",
       "                     min_samples_leaf=7, min_samples_split=11, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# using the tpot model found in audio_TPOT.ipynb\n",
    "pipe = ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=1.0, min_samples_leaf=7, min_samples_split=11, n_estimators=100)\n",
    "\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(pipe, 'random_state'):\n",
    "    setattr(pipe, 'random_state', 42)\n",
    "\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9d7d2eb329fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:  \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall:    \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EVAL\n",
    "preds = pipe.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:  \", round(accuracy_score(y_test, preds),4) )\n",
    "print(\"Precision: \", round(precision_score(y_test, preds),4) )\n",
    "print(\"Recall:    \", round(recall_score(y_test, preds),4) )\n",
    "print(\"F1:        \", round(f1_score(y_test, preds),4) )\n",
    "\n",
    "plot_roc_curve(pipe, x_test, y_test)\n",
    "plt.title(\"ROC on test\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
