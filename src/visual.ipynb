{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n",
      "libopencv                 4.4.0                    py38_2    conda-forge\n",
      "librosa                   0.8.0              pyh9f0ad1d_0    conda-forge\n",
      "numpy                     1.19.2           py38h456fd55_0  \n",
      "numpy-base                1.19.2           py38hcfb5961_0  \n",
      "opencv                    4.4.0                    py38_2    conda-forge\n",
      "pandas                    1.1.3            py38hb1e8313_0  \n",
      "py-opencv                 4.4.0            py38h23f93f0_2    conda-forge\n",
      "scikit-image              0.17.2           py38hcf432d8_4    conda-forge\n",
      "scikit-learn              0.23.2           py38h959d312_0  \n",
      "seaborn                   0.11.0                     py_0  \n"
     ]
    }
   ],
   "source": [
    "#!python --version\n",
    "#!conda list |grep -E \"pandas|numpy|seaborn|librosa|opencv|scikit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import visual_feat_ext\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature file already exists... skipping\n",
      "feature file already exists... skipping\n",
      "feature file already exists... skipping\n"
     ]
    }
   ],
   "source": [
    "#import visual_feature_extraction\n",
    "!python 'create_visual_feature_csv.py'\n",
    "\n",
    "### Manually like this\n",
    "#gt1 = pd.read_csv(\"../data/gt/gt_02_04_04.csv.csv\", delimiter=\",\", na_values=\"\")\n",
    "#gt1.fillna(0, inplace=True)\n",
    "#imgs, feats = visual_feat_ext.feats_from_avi(limit_frames=False, frames=4000, one_frame_per_sec=False,\n",
    "#                                            blob_sigma=400, blob_t=0.04,\n",
    "#                                            include_blobs=False, include_hists=True)\n",
    "#df = pd.merge(feats, gt1, left_on=['minute','second'], right_on = ['Min','Sec']).drop([\"Min\",\"Sec\"], axis=1)\n",
    "#df.set_index([\"minute\",\"second\",\"frame\"], inplace=True)\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ostritze/opt/anaconda3/envs/simmod/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (772) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "x_train = pd.read_csv(\"../data/ep1_visual_hists.csv\", delimiter=\",\", na_values=\"\", dtype=int)\n",
    "y_train = x_train[\"kermit_video\"]\n",
    "x_train = x_train.filter(regex=(\"_hist\"))\n",
    "\n",
    "x_test = pd.read_csv(\"../data/ep2_visual_hists.csv\", delimiter=\",\", na_values=\"\")\n",
    "y_test = x_test[\"kermit_video\"]\n",
    "x_test = x_test.filter(regex=(\"_hist\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Hists only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators:  100  --- Depth:  2\n",
      "Accuracy:   0.6708\n",
      "Precision:  0.2432\n",
      "Recall:     0.0007\n",
      "F1:         0.0014\n",
      "Estimators:  250  --- Depth:  2\n",
      "Accuracy:   0.6718\n",
      "Precision:  1.0\n",
      "Recall:     0.0017\n",
      "F1:         0.0035\n",
      "Estimators:  500  --- Depth:  2\n",
      "Accuracy:   0.6716\n",
      "Precision:  1.0\n",
      "Recall:     0.0012\n",
      "F1:         0.0024\n",
      "Estimators:  100  --- Depth:  8\n",
      "Accuracy:   0.7239\n",
      "Precision:  0.9003\n",
      "Recall:     0.1802\n",
      "F1:         0.3003\n",
      "Estimators:  250  --- Depth:  8\n",
      "Accuracy:   0.7252\n",
      "Precision:  0.9117\n",
      "Recall:     0.1818\n",
      "F1:         0.3032\n",
      "Estimators:  500  --- Depth:  8\n",
      "Accuracy:   0.7222\n",
      "Precision:  0.9034\n",
      "Recall:     0.1735\n",
      "F1:         0.2911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "\n",
    "max_depth = [2, 8]\n",
    "n_estimators = [100, 250, 500]\n",
    "for d in max_depth:\n",
    "    for n in n_estimators:\n",
    "        rfor = RandomForestClassifier(n_estimators=n, max_depth=d, random_state=42)\n",
    "        rfor.fit(x_train, y_train)\n",
    "        y_pred = rfor.predict(x_test)\n",
    "        print(\"Estimators: \", n, \" --- Depth: \",d)\n",
    "        print(\"Accuracy:  \", round(accuracy_score(y_test,y_pred),4) )\n",
    "        print(\"Precision: \", round(precision_score(y_test,y_pred),4) )\n",
    "        print(\"Recall:    \", round(recall_score(y_test,y_pred),4) )\n",
    "        print(\"F1:        \", round(f1_score(y_test,y_pred),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers:  (100,)\n",
      "Accuracy:   0.6291\n",
      "Precision:  0.4269\n",
      "Recall:     0.3749\n",
      "F1:         0.3992\n",
      "Layers:  (100, 3)\n",
      "Accuracy:   0.6676\n",
      "Precision:  0.4909\n",
      "Recall:     0.302\n",
      "F1:         0.374\n",
      "Layers:  (100, 5)\n",
      "Accuracy:   0.6573\n",
      "Precision:  0.471\n",
      "Recall:     0.3443\n",
      "F1:         0.3978\n",
      "Layers:  (256, 3)\n",
      "Accuracy:   0.6712\n",
      "Precision:  0.0\n",
      "Recall:     0.0\n",
      "F1:         0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ostritze/opt/anaconda3/envs/simmod/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/ostritze/opt/anaconda3/envs/simmod/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers:  (256, 5)\n",
      "Accuracy:   0.6984\n",
      "Precision:  0.5782\n",
      "Recall:     0.3049\n",
      "F1:         0.3993\n"
     ]
    }
   ],
   "source": [
    "# Try a MLP for comparison\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "### need to scale first\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "\n",
    "hidden_layer_sizes = [(100,), (100,3), (100,5), (256,3), (256, 5)]\n",
    "\n",
    "for hlayer in hidden_layer_sizes:\n",
    "    mlp = MLPClassifier(random_state=42, max_iter=300, hidden_layer_sizes=hlayer,\n",
    "                        n_iter_no_change=25,\n",
    "                        shuffle=False, verbose=False)\n",
    "    mlp.fit(x_train_scaled, y_train)\n",
    "    y_pred = mlp.predict(scaler.transform(x_test))\n",
    "    print(\"Layers: \", hlayer)\n",
    "    print(\"Accuracy:  \", round(accuracy_score(y_test,y_pred),4) )\n",
    "    print(\"Precision: \", round(precision_score(y_test,y_pred),4) )\n",
    "    print(\"Recall:    \", round(recall_score(y_test,y_pred),4) )\n",
    "    print(\"F1:        \", round(f1_score(y_test,y_pred),4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers:  (100,)\n",
    "Accuracy:   0.6291\n",
    "Precision:  0.4269\n",
    "Layers:  (100, 3)\n",
    "Accuracy:   0.6676\n",
    "Precision:  0.4909\n",
    "Layers:  (100, 5)\n",
    "Accuracy:   0.6573\n",
    "Precision:  0.471\n",
    "Layers:  (256, 3)\n",
    "Accuracy:   0.6712\n",
    "Precision:  0.0\n",
    "Layers:  (256, 5)\n",
    "Accuracy:   0.6984\n",
    "Precision:  0.5782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = pd.read_csv(\"../data/ep3_visual_hists.csv\", delimiter=\",\", na_values=\"\")\n",
    "y_val = x_val[\"kermit_video\"]\n",
    "x_val = x_val.filter(regex=(\"_hist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.5286\n",
      "Precision:  0.3441\n",
      "Recall:     0.0137\n",
      "F1:         0.0263\n"
     ]
    }
   ],
   "source": [
    "# best performer above...\n",
    "rfor = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=42)\n",
    "rfor.fit(x_train, y_train)\n",
    "y_pred = rfor.predict(x_val)\n",
    "print(\"Accuracy:  \", round(accuracy_score(y_val,y_pred),4) )\n",
    "print(\"Precision: \", round(precision_score(y_val,y_pred),4) )\n",
    "print(\"Recall:    \", round(recall_score(y_val,y_pred),4) )\n",
    "print(\"F1:        \", round(f1_score(y_val,y_pred),4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all set!\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"../data/ep1_visual_full.csv\", delimiter=\",\", na_values=\"\").fillna(0)\n",
    "y_train = x_train[\"kermit_video\"]\n",
    "#x_train = x_train.filter(regex=(\"_blob|_hist\"))\n",
    "x_train = x_train.filter(regex=(\"_blob\"))\n",
    "\n",
    "x_test = pd.read_csv(\"../data/ep2_visual_full.csv\", delimiter=\",\", na_values=\"\").fillna(0)\n",
    "y_test = x_test[\"kermit_video\"]\n",
    "#x_test = x_test.filter(regex=(\"_blob|_hist\"))\n",
    "x_test = x_test.filter(regex=(\"_blob\"))\n",
    "\n",
    "x_val = pd.read_csv(\"../data/ep3_visual_full.csv\", delimiter=\",\", na_values=\"\").fillna(0)\n",
    "y_val = x_val[\"kermit_video\"]\n",
    "#x_test = x_test.filter(regex=(\"_blob|_hist\"))\n",
    "x_val = x_val.filter(regex=(\"_blob\"))\n",
    "\n",
    "# bring to same shape\n",
    "cols = list(x_val.iloc[:,(x_train.shape[1]-x_val.shape[1]):].columns)\n",
    "for col in cols:\n",
    "    x_train[col] = 0\n",
    "\n",
    "cols = list(x_val.iloc[:,(x_test.shape[1]-x_val.shape[1]):].columns)\n",
    "for col in cols:\n",
    "    x_test[col] = 0\n",
    "\n",
    "if x_val.shape[1] == x_test.shape[1] == x_train.shape[1]:\n",
    "    print(\"all set!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b4aaa75c04470ab0635c35e3097e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=90.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8558018396774032\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8558018396774032\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8558018396774032\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8677441710240009\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8677441710240009\n",
      "\n",
      "Best pipeline: MLPClassifier(MLPClassifier(LogisticRegression(input_matrix, C=15.0, dual=False, penalty=l2), alpha=0.0001, learning_rate_init=0.001), alpha=0.0001, learning_rate_init=0.01)\n",
      "0.8095693285452243\n",
      "Accuracy:   0.8096\n",
      "Precision:  0.8417\n",
      "Recall:     0.5182\n",
      "F1:         0.6415\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score, precision_score\n",
    "from tpot import TPOTClassifier\n",
    "pipe = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=15,\n",
    "    cv=4,\n",
    "    random_state=42,\n",
    "    verbosity=2\n",
    ")\n",
    "pipe.fit(x_train, y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "print(pipe.score(x_test, y_test))\n",
    "print(\"Accuracy:  \", round(accuracy_score(y_test,y_pred),4) )\n",
    "print(\"Precision: \", round(precision_score(y_test,y_pred),4) )\n",
    "print(\"Recall:    \", round(recall_score(y_test,y_pred),4) )\n",
    "print(\"F1:        \", round(f1_score(y_test,y_pred),4) )\n",
    "pipe.export(\"blobs_tpot.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5802748123327879\n",
      "Accuracy:   0.5803\n",
      "Precision:  0.721\n",
      "Recall:     0.1607\n",
      "F1:         0.2629\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(x_val)\n",
    "print(pipe.score(x_val, y_val))\n",
    "print(\"Accuracy:  \", round(accuracy_score(y_val,y_pred),4) )\n",
    "print(\"Precision: \", round(precision_score(y_val,y_pred),4) )\n",
    "print(\"Recall:    \", round(recall_score(y_val,y_pred),4) )\n",
    "print(\"F1:        \", round(f1_score(y_val,y_pred),4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ostritze/opt/anaconda3/envs/simmod/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (787) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all set!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_train = pd.read_csv(\"../data/ep1_visual_full.csv\", delimiter=\",\", na_values=\"\").fillna(0)\n",
    "y_train = x_train[\"kermit_video\"]\n",
    "#x_train = x_train.filter(regex=(\"_blob|_hist\"))\n",
    "x_train = x_train.filter(regex=(\"_hist|_blob\"))\n",
    "\n",
    "x_test = pd.read_csv(\"../data/ep2_visual_full.csv\", delimiter=\",\", na_values=\"\").fillna(0)\n",
    "y_test = x_test[\"kermit_video\"]\n",
    "#x_test = x_test.filter(regex=(\"_blob|_hist\"))\n",
    "x_test = x_test.filter(regex=(\"_hist|_blob\"))\n",
    "\n",
    "x_val = pd.read_csv(\"../data/ep3_visual_full.csv\", delimiter=\",\", na_values=\"\").fillna(0)\n",
    "y_val = x_val[\"kermit_video\"]\n",
    "#x_test = x_test.filter(regex=(\"_blob|_hist\"))\n",
    "x_val = x_val.filter(regex=(\"_hist|_blob\"))\n",
    "\n",
    "# bring to same shape\n",
    "cols = list(x_val.iloc[:,(x_train.shape[1]-x_val.shape[1]):].columns)\n",
    "for col in cols:\n",
    "    x_train[col] = 0\n",
    "\n",
    "cols = list(x_val.iloc[:,(x_test.shape[1]-x_val.shape[1]):].columns)\n",
    "for col in cols:\n",
    "    x_test[col] = 0\n",
    "\n",
    "if x_val.shape[1] == x_test.shape[1] == x_train.shape[1]:\n",
    "    print(\"all set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9623aade6842c18fe7ca328f00bd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9080709373868983\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9080709373868983\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9080709373868983\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=0.25, min_samples_leaf=8, min_samples_split=11, n_estimators=100)\n",
      "0.7630919471930142\n",
      "Accuracy:   0.7631\n",
      "Precision:  0.9209\n",
      "Recall:     0.3056\n",
      "F1:         0.4589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "import tpot\n",
    "pipe = tpot.TPOTClassifier(\n",
    "    generations=3,\n",
    "    population_size=10,\n",
    "    cv=2,\n",
    "    random_state=42,\n",
    "    verbosity=2\n",
    ")\n",
    "pipe.fit(x_train, y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "print(pipe.score(x_test, y_test))\n",
    "print(\"Accuracy:  \", round(accuracy_score(y_test,y_pred),4) )\n",
    "print(\"Precision: \", round(precision_score(y_test,y_pred),4) )\n",
    "print(\"Recall:    \", round(recall_score(y_test,y_pred),4) )\n",
    "print(\"F1:        \", round(f1_score(y_test,y_pred),4) )\n",
    "pipe.export(\"visual_tpot.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567001740304943\n",
      "Accuracy:   0.567\n",
      "Precision:  0.8145\n",
      "Recall:     0.0907\n",
      "F1:         0.1632\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(x_val)\n",
    "print(pipe.score(x_val, y_val))\n",
    "print(\"Accuracy:  \", round(accuracy_score(y_val,y_pred),4) )\n",
    "print(\"Precision: \", round(precision_score(y_val,y_pred),4) )\n",
    "print(\"Recall:    \", round(recall_score(y_val,y_pred),4) )\n",
    "print(\"F1:        \", round(f1_score(y_val,y_pred),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8.5 (simmod)",
   "language": "python",
   "name": "simmod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
